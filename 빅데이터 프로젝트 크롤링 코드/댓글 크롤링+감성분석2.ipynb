{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd016ce5-ccfa-4a3d-a577-fa9bf7ce38eb",
   "metadata": {},
   "source": [
    "# 영화 리뷰 데이터로 감성 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f436968-9a49-468c-961d-472f54034c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#warning 메시지 표시 안함\n",
    "import schedule\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import pymysql\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85d9343f-8029-4326-bdb5-db8b7aac7b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31448 entries, 0 to 31447\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   document  31448 non-null  object\n",
      " 1   label     31448 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 491.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 31448 entries, 0 to 31447\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   document  31448 non-null  object\n",
      " 1   label     31448 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 737.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21506 entries, 0 to 21505\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        21506 non-null  int64 \n",
      " 1   document  21504 non-null  object\n",
      " 2   label     21506 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 504.2+ KB\n",
      "  (0, 213483)\t0.17837050707344645\n",
      "  (0, 213448)\t0.07323524334181673\n",
      "  (0, 202045)\t0.16913084744683635\n",
      "  (0, 202044)\t0.13328170396797387\n",
      "  (0, 185910)\t0.1613341783282592\n",
      "  (0, 185879)\t0.13698319978798945\n",
      "  (0, 167586)\t0.10458004659219602\n",
      "  (0, 151665)\t0.15049675974349927\n",
      "  (0, 150584)\t0.04536374118618066\n",
      "  (0, 131994)\t0.21439680287469137\n",
      "  (0, 131944)\t0.13419166280090372\n",
      "  (0, 124452)\t0.18920792565820635\n",
      "  (0, 124440)\t0.2062442544033936\n",
      "  (0, 123355)\t0.10401013427254856\n",
      "  (0, 123290)\t0.21439680287469137\n",
      "  (0, 123229)\t0.13997598799457953\n",
      "  (0, 112626)\t0.21439680287469137\n",
      "  (0, 112613)\t0.1319063536965388\n",
      "  (0, 95787)\t0.15092007345296304\n",
      "  (0, 95782)\t0.13475808500433706\n",
      "  (0, 90364)\t0.12006947299902083\n",
      "  (0, 90334)\t0.08124907836338825\n",
      "  (0, 85398)\t0.21439680287469137\n",
      "  (0, 85380)\t0.13948555737575782\n",
      "  (0, 84397)\t0.2062442544033936\n",
      "  :\t:\n",
      "  (8, 14543)\t0.1937050877298557\n",
      "  (8, 9297)\t0.17294050882600837\n",
      "  (8, 9296)\t0.16636435721390164\n",
      "  (8, 2006)\t0.17294050882600837\n",
      "  (8, 959)\t0.17294050882600837\n",
      "  (8, 760)\t0.08834242783667354\n",
      "  (9, 220225)\t0.29145777489800045\n",
      "  (9, 220222)\t0.24029463487657576\n",
      "  (9, 149355)\t0.22469957529041684\n",
      "  (9, 148640)\t0.08283657958216688\n",
      "  (9, 115673)\t0.24746600146927214\n",
      "  (9, 115672)\t0.19097114850194194\n",
      "  (9, 105365)\t0.29145777489800045\n",
      "  (9, 101438)\t0.29145777489800045\n",
      "  (9, 101202)\t0.13925473066121763\n",
      "  (9, 99855)\t0.29145777489800045\n",
      "  (9, 99849)\t0.20823993825809686\n",
      "  (9, 90519)\t0.27251154933417115\n",
      "  (9, 90506)\t0.14097710353585743\n",
      "  (9, 30847)\t0.29145777489800045\n",
      "  (9, 30821)\t0.13213155736751422\n",
      "  (9, 14596)\t0.2664122270331014\n",
      "  (9, 14543)\t0.16322622802320336\n",
      "  (9, 2985)\t0.29145777489800045\n",
      "  (9, 760)\t0.07444203680546767\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "{'C': 5} 0.9532\n",
      "감성 분석 정확도 :  0.538\n"
     ]
    }
   ],
   "source": [
    "#사전 로딩 데이터(약 4분 소요)\n",
    "\n",
    "# 훈련용 데이터인 ratings_train.txt 파일을 주피터 노트북에서 로드\n",
    "nsmc_train_df = pd.read_csv('./train.txt', encoding = 'utf8', sep = ',', engine = 'python', names=['document','label'])\n",
    "nsmc_train_df\n",
    "\n",
    "# 훈련용 데이터셋의 정보를 확인\n",
    "nsmc_train_df.info()\n",
    "\n",
    "# 결측치 제거하기\n",
    "nsmc_train_df = nsmc_train_df[nsmc_train_df['document'].notnull()]\n",
    "\n",
    "# 수정된 nsmc_train_df의 정보를 다시 확인\n",
    "nsmc_train_df.info()\n",
    "\n",
    "# 감성 분류 클래스의 구성을 확인\n",
    "nsmc_train_df['label'].value_counts()\n",
    "\n",
    "# 평가용 데이터인 ratings_test.txt 파일을 로드\n",
    "nsmc_test_df = pd.read_csv('ratings_test.txt', encoding = 'utf8', sep = '\\t', engine = 'python')\n",
    "nsmc_test_df.head()\n",
    "nsmc_test_df.info()\n",
    "\n",
    "#document 칼럼이 Null인 샘플 제거\n",
    "nsmc_test_df = nsmc_test_df[nsmc_test_df['document'].notnull()] \n",
    "\n",
    "nsmc_test_df['label'].value_counts()\n",
    "\n",
    "nsmc_test_df['document'] = nsmc_test_df['document'].apply(lambda x : re.sub(r'[^ ㄱ-ㅣ가-힣]+', \" \", x))\n",
    "nsmc_test_df.head()\n",
    "\n",
    "# 분석모델 구축\n",
    "# 형태소 분석에 사용할 konlpy 패키지의 Okt 클래스를 임포트하고 okt 객체를 생성\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "# 문장을 토큰화하기 위해 okt_tokenizer 함수를 정의하고 \n",
    "# okt.morphs() 함수를 사용하여 형태소 단위로 토큰화 작업을 수행\n",
    "def okt_tokenizer(text):\n",
    "    tokens = okt.morphs(text)\n",
    "    return tokens\n",
    "\n",
    "#사이킷런의 TfidfVectorizer를 이용하여 TF-IDF 벡터화에 사용할 tfidf 객체를 생성\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 토큰의 단어 크기ngram_range는 1~2개 단어로 함\n",
    "# 토큰은 출현 빈도가 최소min_df 1번 이상이고 최대 max_df 90% 이하인 것만 사용\n",
    "tfidf = TfidfVectorizer(tokenizer = okt_tokenizer, ngram_range = (1, 2), min_df = 1, max_df = 0.9)\n",
    "\n",
    "# 벡터화할 데이터nsmc_train_df['document']에 대해 벡터 모델 tfidf의 내부 설정값을 조정fit( )\n",
    "tfidf.fit(nsmc_train_df['document'])\n",
    "\n",
    "# 벡터로 변환을 수행\n",
    "nsmc_train_tfidf = tfidf.transform(nsmc_train_df['document'])\n",
    "\n",
    "#벡터로 변환된 분석모델 확인\n",
    "print(nsmc_train_tfidf[:10])\n",
    "\n",
    "#감성 분류 모델 구축\n",
    "# 사이킷런의 LogisticRegression 클래스에 대해 객체 SA_lr을 생성\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "SA_lr = LogisticRegression(random_state = 0)\n",
    "\n",
    "# nsmc_train_tfidf를 독립변수 X로 하고 label 컬럼을 종속 변수 Y로 하여 \n",
    "# 로지스틱 회귀 모델SA_lr의 내부 설정값을 조정fit( )\n",
    "SA_lr.fit(nsmc_train_tfidf, nsmc_train_df['label'])\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#하이퍼 매개변수 C에 대해 비교 검사를 할 6개 값[1, 3, 3.5, 4, 4.5, 5]을 params로 하고,\n",
    "params = {'C': [1, 3, 3.5, 4, 4.5, 5]}\n",
    "\n",
    "# 교차 검증cv을 3, 모형 비교 기준은 정확도로 설정, scoring='accuracy'하여 GridSearchCV 객체를 생성\n",
    "SA_lr_grid_cv = GridSearchCV(SA_lr, param_grid = params, cv = 3, scoring = 'accuracy', verbose = 1)\n",
    "\n",
    "# GridSearchCV 객체에 nsmc_train_tfidf와 label 컬럼에 대해 설정값을 조정fit( ) \n",
    "SA_lr_grid_cv.fit(nsmc_train_tfidf, nsmc_train_df['label'])\n",
    "\n",
    "# GridSearchCV에 의해 찾은 최적의 C 매개변수 best_params와 최고 점수 best_score를 출력하여 확인\n",
    "print(SA_lr_grid_cv.best_params_, round(SA_lr_grid_cv.best_score_, 4))\n",
    "\n",
    "##최적 매개변수의 best 모델 저장\n",
    "SA_lr_best = SA_lr_grid_cv.best_estimator_\n",
    "\n",
    "#분석모델 평가\n",
    "#평가용 데이터의 피처 벡터화\n",
    "# 평가용 데이터 nsmc_test_df['document']에 tfidf 객체를 적용하여 벡터 변환을 수행 transform( )\n",
    "nsmc_test_tfidf = tfidf.transform(nsmc_test_df['document'])\n",
    "\n",
    "#감성 분류 모델SA_lr_best에 nsmc_test_tfidf 벡터를 사용하여 감성을 예측 predict( )\n",
    "test_predict = SA_lr_best.predict(nsmc_test_tfidf)\n",
    "\n",
    "# 평가용 데이터의 감성 결과값 nsmc_test_df['label']과 \n",
    "# 감성 예측값test_predict을 기반으로 정확도를 계산 accuracy_score( )하여 출력\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('감성 분석 정확도 : ', round(accuracy_score(nsmc_test_df['label'], test_predict), 3))\n",
    "\n",
    "\n",
    "#코멘트 테이블에 감석분석결과 업뎃하는 메서드\n",
    "def emotional(data):\n",
    "    conn=pymysql.connect(\n",
    "        user='root',\n",
    "        passwd='1234',\n",
    "        host='localhost',\n",
    "        db='travel',\n",
    "        charset='utf8')\n",
    "    cursor=conn.cursor()\n",
    "    sql = 'update comment set emotion = %s where cid=%s'\n",
    "    cursor.execute(sql, data)\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "#크롤링 준비\n",
    "path = 'C:/devtools/pythonwork/Lesson/chromedriver'\n",
    "\n",
    "# 구글 사이트 접근 환경 설정 완료\n",
    "driver = webdriver.Chrome(path)\n",
    "action = ActionChains(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc34a4f3-7388-4ae2-bec2-1a396e04b44e",
   "metadata": {},
   "source": [
    "# 새로운 텍스트로 감성 예측 확인하기\n",
    "1. 감성 분류 모델에 새로운 텍스트를 직접 입력하여 감성 예측을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd17ebd1-8d4e-4979-acf8-52ec62f0fc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['요리보고']\n",
      "['요리보고']\n",
      "[]\n",
      "[]\n",
      "['댓글', '작성']\n",
      "['댓글 작성']\n",
      "['댓글', '시간출력']\n",
      "['댓글 시간출력']\n",
      "['시간이']\n",
      "['시간이']\n",
      "['검색', '완료된', '관광지의', '해시태그', '뿌려주기']\n",
      "['검색 완료된 관광지의 해시태그 뿌려주기']\n",
      "['좋아요']\n",
      "['좋아요']\n",
      "['이뻐요']\n",
      "['이뻐요']\n",
      "['아름다워요']\n",
      "['아름다워요']\n",
      "['사진', '찍기', '좋습니다']\n",
      "['사진 찍기 좋습니다']\n",
      "['들어가라']\n",
      "['들어가라']\n",
      "['댓글', '테스트']\n",
      "['댓글 테스트']\n",
      "['좋아요']\n",
      "['좋아요']\n",
      "['싫어요']\n",
      "['싫어요']\n",
      "['이뻐요']\n",
      "['이뻐요']\n",
      "['별로에여']\n",
      "['별로에여']\n",
      "['너무', '좋아']\n",
      "['너무 좋아']\n",
      "['너무', '싫어']\n",
      "['너무 싫어']\n",
      "['아이', '좋아']\n",
      "['아이 좋아']\n",
      "['아이', '싫어']\n",
      "['아이 싫어']\n",
      "['별로에여']\n",
      "['별로에여']\n",
      "['좋아']\n",
      "['좋아']\n",
      "['별로에여']\n",
      "['별로에여']\n",
      "['좋아']\n",
      "['좋아']\n",
      "['별로에여']\n",
      "['별로에여']\n",
      "['야경', '너무', '이뻐요']\n",
      "['야경 너무 이뻐요']\n",
      "['사람', '많아서', '불편했어요']\n",
      "['사람 많아서 불편했어요']\n",
      "['어린왕자', '동상이랑', '사진찍기', '좋아요', '음식이', '너무', '비싸요']\n",
      "['어린왕자 동상이랑 사진찍기 좋아요 음식이 너무 비싸요']\n",
      "['야경', '너무', '이뻐요']\n",
      "['야경 너무 이뻐요']\n",
      "['별로에요']\n",
      "['별로에요']\n",
      "['바다', '너무', '시원해서', '좋았어요']\n",
      "['바다 너무 시원해서 좋았어요']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def do_emotion():\n",
    "    # 관광지 번호만큼 반복문 실행\n",
    "    for i in range(10):\n",
    "\n",
    "        num = i+1\n",
    "        url = 'http://localhost:8080/busan/' + str(num)\n",
    "\n",
    "        # 검색한 관광지의 리뷰 화면 호출\n",
    "        driver.implicitly_wait(2)\n",
    "        driver.get(url)\n",
    "        driver.set_window_size(700, 900)\n",
    "        driver.implicitly_wait(1)\n",
    "        #리뷰 갯수 가져오기\n",
    "        #/html/body/div/div[4]/h6\n",
    "        review_count = driver.find_elements_by_id('/html/body/div/div[4]/h6/span[2]')\n",
    "        # 리뷰 갯수만큼 리뷰리스트 담기\n",
    "        driver.implicitly_wait(2)\n",
    "        review_count = driver.find_elements_by_xpath('/html/body/div/div[4]/h6/span[2]')\n",
    "        total_review=0;\n",
    "        #리뷰갯수 담을 객체 생성\n",
    "        for i in review_count:\n",
    "    #        print(i.text)\n",
    "            total_review = int(i.text)\n",
    "            #리뷰 갯수만큼 for문\n",
    "            for j in range(total_review):\n",
    "                k=j+1\n",
    "                review=''\n",
    "                cid=0\n",
    "                driver.implicitly_wait(2)\n",
    "                review_crawling = driver.find_elements_by_xpath('/html/body/div/div[4]/table/tbody/tr['+str(k)+']/td[3]')\n",
    "                cid_crawling = driver.find_elements_by_xpath('/html/body/div/div[4]/table/tbody/tr['+str(k)+']/td[1]')\n",
    "                for l in review_crawling:\n",
    "                    driver.implicitly_wait(2)\n",
    "                    review_crawling = driver.find_elements_by_xpath('/html/body/div/div[4]/table/tbody/tr['+str(k)+']/td[3]')\n",
    "                    review = str(l.text)\n",
    "                for m in cid_crawling:               \n",
    "                    cid_crawling = driver.find_elements_by_xpath('/html/body/div/div[4]/table/tbody/tr['+str(k)+']/td[1]')\n",
    "                    cid = int(m.text)\n",
    "    #                print(cid)\n",
    "    #                print(review)\n",
    "                    data=(cid, cid)\n",
    "                    emotional(data)\n",
    "\n",
    "                    #0) 크롤링 텍스트에 대한 전처리 수행\n",
    "                    review = re.compile(r'[ㄱ-ㅣ가-힣]+').findall(review) ; print(review)\n",
    "\n",
    "                    # 전처리 후 배열에 담긴 문자가 없을 경우(ex: 영어 숫자 이모티콘만 존재) : 0(중립감성)\n",
    "                    if (len(review)==0):\n",
    "                        data = (0,cid )\n",
    "                        emotional(data)\n",
    "                    else :\n",
    "                        review = [\" \".join(review)] ; print(review)\n",
    "                        #1) 입력 텍스트의 피처 벡터화\n",
    "                        st_tfidf = tfidf.transform(review)\n",
    "                        st_tfidf\n",
    "                        #2) 최적 감성 분석 모델에 적용하여 감성 분석 평가\n",
    "                        st_predict = SA_lr_best.predict(st_tfidf)\n",
    "                        st_predict\n",
    "\n",
    "                        #1) 입력 텍스트의 피처 벡터화\n",
    "                        st_tfidf = tfidf.transform(review)\n",
    "                        #print(st_tfidf)\n",
    "\n",
    "                        #2) 최적 감성 분석 모델에 적용하여 감성 분석 평가\n",
    "                        st_predict = SA_lr_best.predict(st_tfidf)\n",
    "                        #print(st_predict)\n",
    "\n",
    "                        if(st_predict == 0):\n",
    "                            # 부정 : emotion=1\n",
    "                            data = (1,cid )\n",
    "                            emotional(data)\n",
    "                        else :\n",
    "                            # 긍정 : emotion=2\n",
    "                            data = (2,cid )\n",
    "                            emotional(data)\n",
    "do_emotion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f43128a-499c-4aea-947a-73429cb61923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한국전쟁', '피란민들의', '애환이', '서려', '있는', '장소입니다', '지금은', '부산', '원도심의', '추억도', '어려', '있는', '곳이기도', '하며', '부산', '지역', '문화', '예술계에서', '일하는', '분들이', '모여', '또따또가라는', '문화예술지역으로', '개발하는', '곳이기도', '하지요', '계단', '문화관을', '포함하여', '지역', '골목골목을', '천천히', '둘러보면', '아기자기한', '재미가', '있습니다']\n",
      "['한국전쟁 피란민들의 애환이 서려 있는 장소입니다 지금은 부산 원도심의 추억도 어려 있는 곳이기도 하며 부산 지역 문화 예술계에서 일하는 분들이 모여 또따또가라는 문화예술지역으로 개발하는 곳이기도 하지요 계단 문화관을 포함하여 지역 골목골목을 천천히 둘러보면 아기자기한 재미가 있습니다']\n",
      "['별로', '지루', '아쉽다']\n",
      "['별로 지루 아쉽다']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['해변에서', '바라보는', '광안대교', '야경이', '정말', '예뻣어요']\n",
      "['해변에서 바라보는 광안대교 야경이 정말 예뻣어요']\n",
      "['하루종일', '바라보고', '있어도', '질리지', '않을', '풍경']\n",
      "['하루종일 바라보고 있어도 질리지 않을 풍경']\n",
      "[]\n",
      "['ㅈㄷ', '겨ㅑㅅ퍄ㅕㅁㄷ', 'ㅛ소ㅓ']\n",
      "['ㅈㄷ 겨ㅑㅅ퍄ㅕㅁㄷ ㅛ소ㅓ']\n",
      "['ㅇㄱ', 'ㅑㅌ교어ㅕㅇ뇨ㅓㅏㅌㄹ화넌교ㅑㅌ셔아ㅓ오ㅓㅇ서셔ㅏ셔', 'ㅐㅇ', 'ㅐㅑ쇼ㅓㄴ쇼ㅓㅏㅇ셔ㅏㅇ셔ㅏㅣ야ㅣㅇㄹ']\n",
      "['ㅇㄱ ㅑㅌ교어ㅕㅇ뇨ㅓㅏㅌㄹ화넌교ㅑㅌ셔아ㅓ오ㅓㅇ서셔ㅏ셔 ㅐㅇ ㅐㅑ쇼ㅓㄴ쇼ㅓㅏㅇ셔ㅏㅇ셔ㅏㅣ야ㅣㅇㄹ']\n",
      "['ㄷ', 'ㅕ얼퇕호']\n",
      "['ㄷ ㅕ얼퇕호']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['ㅀㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎ']\n",
      "['ㅀㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎ']\n",
      "['ㅕ요ㅕㅇ롱로ㅓㄹㅇ홓로롤홀홓롷ㄹㄹㄹㄴ', 'ㅛㄴ굔', 'ㅕㄴ거뇨ㅏㄴ셔ㅏㅇ셔ㅣㅏㄴ고논교ㅓㄴ교ㅏㅓㄴㄱ']\n",
      "['ㅕ요ㅕㅇ롱로ㅓㄹㅇ홓로롤홀홓롷ㄹㄹㄹㄴ ㅛㄴ굔 ㅕㄴ거뇨ㅏㄴ셔ㅏㅇ셔ㅣㅏㄴ고논교ㅓㄴ교ㅏㅓㄴㄱ']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['별로']\n",
      "['별로']\n",
      "['별로', '지루', '아쉽']\n",
      "['별로 지루 아쉽']\n"
     ]
    }
   ],
   "source": [
    "# 8시간마다 do()실행 (seconds, minutes, hours, days, weeks)\n",
    "schedule.every(8).hours.do(do_emotion)\n",
    "while True:\n",
    "    schedule.run_pending()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
